# 딥러닝을 구동하는 데 필요한 케라스 함수를 불러옵니다.
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# 필요한 라이브러리를 불러옵니다.
import numpy as np
import tensorflow as tf

# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분입니다.
np.random.seed(3)
tf.random.set_seed(3)

# 준비된 수술 환자 데이터를 불러들입니다.
Data_set = np.loadtxt("../dataset/ThoraricSurgery.csv", delimiter=",")

# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장합니다.
X = Data_set[:,0:17]
Y = Data_set[:,17]

# 딥러닝 구조를 결정합니다(모델을 설정하고 실행하는 부분입니다).
model = Sequential() # perceptron을 만드는 것 
#model.add가 두개이므로 이 perceptron은 층이 2개 
model.add(Dense(30, input_dim=17, activation='relu')) # 은닉층 (출력층을 제외한 층을 모두 은닉층이라고해)
#dense는 몇개의 노드를 만들 것인지, input dim은 몇개의 변수를 받을 것인지, activation은 활성함수를 뭐로 할지
#keras는 입력층을 따로 만드는 것이 아니라 첫번째 은닉층에 input dim으로 첫번째 dense가 은닉층 +입력층 역할
model.add(Dense(1, activation='sigmoid')) #출력층 (마지막 층)

# 딥러닝을 실행합니다.
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])
#만든 multy perceptron을 실핼할때 옵션들 넣어주는거, loss는 어떤 오차방법을 선택할지,optimizer는 오류역전파 방법,
# 만든 모델을 실행시키는 거
#각 샘플에 대해 한번 실행하는 것을 1epochs, epochs = n  n번 반복
#batch_size는 샘플을 한번에 몇개씩 처리할지 정하는 부분 
# ex) batch_size = 10은 0470개의 샘플을 10개씩 끊어서 집어넣으라는 뜻
# batch_size가 너무 크면 학습속도가 느리고, 너무 작으면 실행 값의 편차가 생김, 
model.fit(X, Y, epochs=100, batch_size=10)


# loss에 교차 엔트로피 방법도 있음(binary_crossentropy) 
